{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hands on Convolutional Neural Networks + Prediction Interpretability.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZackAkil/Hands-on-Convolutional-Neural-Networks-Prediction-Interpretability/blob/master/Hands_on_Convolutional_Neural_Networks_%2B_Prediction_Interpretability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDqWvp6i9pq",
        "colab_type": "text"
      },
      "source": [
        "# üß†üîç Hands on Convolutional Neural Networks + Prediction Interpretability\n",
        "\n",
        "This notebook will walk you through the process of building a CNN model for predicting [American Sign Language (**ASL**) Guestures](https://en.wikipedia.org/wiki/American_manual_alphabet) using [Keras](https://keras.io/), and then do prediction interpretability using [SHAP](https://github.com/slundberg/shap)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcDTotYUjYWu",
        "colab_type": "text"
      },
      "source": [
        "First we will import our data\n",
        "\n",
        "---\n",
        "**Practicle note ‚ö°**: becuase we are importing data direct from Cloud Storage into Colab, the data never touches our local computer and is leveraging the super fast  download speeds between Google services.\n",
        "\n",
        "Download the data using the following command:\n",
        "\n",
        "```bash\n",
        "!gsutil cp \"gs://fun-datasets/asl_mnist.csv\" .\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fExYs1tTjXLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] downlaod data using gsutil \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IJGu2nPqmKK",
        "colab_type": "text"
      },
      "source": [
        "Now that the CSV file of our data in donwloaded, we can load it in using [pandas](https://pandas.pydata.org/):\n",
        "\n",
        "```python\n",
        "# this is how you import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# then read in the CSV file \n",
        "data = pd.read_csv(\"FILE NAME OF CSV\")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D67XpYaqiLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] import pandas and read in csv \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eGAVra40aLs",
        "colab_type": "text"
      },
      "source": [
        "### Looking at the data\n",
        "You should have a look at your data:\n",
        "\n",
        " ```python\n",
        "# display the top couple of rows of a pandas dataframe\n",
        "my_data.head()\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTTmgFyY0zWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] display the first couple of rows of your data using .head()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-R8FZGJ7Zgh",
        "colab_type": "text"
      },
      "source": [
        "## Let's split out data into our inputs (images) and our outputs (ASL labels)\n",
        "\n",
        "```python\n",
        "# assign the label column to a varible y\n",
        "y = data['label'].values\n",
        "\n",
        "# assign the rest to a varible X\n",
        "X = data.drop('label', axis = 1).values / 255.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOq0Y8xd8dq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] split your data into X (inputs) and y (outputs)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm5FFRrT8vVh",
        "colab_type": "text"
      },
      "source": [
        "## Let's actually look at one of these images\n",
        "Print out the first image:\n",
        "```python\n",
        "print(X[0])\n",
        "```\n",
        "#### WHAT DO YOU EXPECT TO SEE?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyJqQxq18o9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] print the first image (what do you expect)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07rSiCos1Zq1",
        "colab_type": "text"
      },
      "source": [
        "## Where's our image!? üò°\n",
        "\n",
        "So we tried to print our image but got a long list of numbers, WTF?\n",
        "\n",
        "Well this is becuase it's easy to store pixel lists in CSV files. \n",
        "\n",
        "What we have todo is reshape the list into a matrix (image shape), then we can view it like a normal image. \n",
        "\n",
        "Todo that we need to know the original dimensions of the image.... it's **`28x28`** (you're welcome üòâ)\n",
        "\n",
        "There is a handy function in [numpy](https://www.numpy.org/) that will do this \"reshaping\" for us:\n",
        "\n",
        "\n",
        "![alt text](https://storage.googleapis.com/random-assets/images/reshape.png)\n",
        "\n",
        "\n",
        "So let's reshape the first image again, then display it using [matplotlib](https://matplotlib.org/):\n",
        "\n",
        "```python\n",
        "#import numpy\n",
        "import numpy as np\n",
        "\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# reshape image\n",
        "img = np.reshape(X[0], (original image height, original image width))\n",
        "\n",
        "# display image\n",
        "plt.imshow(img)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yxoVyasGM_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[TASK] display the first image propery\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4E2JpqtG1c4",
        "colab_type": "text"
      },
      "source": [
        "OK assuming you've displayed one image correctly lets look at a couple of images:\n",
        "\n",
        "Run the following code to see the first 5 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SDZyv5kHA_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the first 5 images\n",
        "\n",
        "# loop 5 times\n",
        "for i in range(5):\n",
        "  # reshape image\n",
        "  img = np.reshape(X[i], (28, 28))\n",
        "  # display image\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o82mbHWHg48",
        "colab_type": "text"
      },
      "source": [
        "Cool! We can see the images, but what do they mean??\n",
        "\n",
        "Let's display them along side their labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob-7i95_HrRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the first 5 images with their labels\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  # display label\n",
        "  print(y[i])\n",
        "\n",
        "  img = np.reshape(X[i], (28, 28))\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERnOgV6HICP6",
        "colab_type": "text"
      },
      "source": [
        "Ok so are labels are **numbers**, not **letters**? üòï\n",
        "\n",
        "I want to see something like this:\n",
        "\n",
        "![alt text](https://storage.googleapis.com/kagglesdsdata/datasets/3258/5337/amer_sign2.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1561653295&Signature=hyygVqicdnvcUYesCK7%2FhMI12AtlnAS0BemhN4IWXEzLs4rLxTRU8Vre09S%2BozCb0YAbteiUXn70YVrr5S8tQGHf2oYYyyNkxBqNJYAXTPSUPVB0Ntr1YlTFUI467XqTGdyzxUZSm3qHYaGbwMr7FWLdUvsNuf7G9CmcHmp4%2BjjNFJHgH6Urawi19CVu%2BWBWmtJXKw4FB2nB%2FZvXZAqf8M2A%2BAur2k%2BBRCG7l4HCH63CUiKT8zHGE85RnjilDrcgzYuPE4KJbqmuKnkHch7FdXK3JraDAIqZldq92aiQsdgtDT7TciPzsCKfSxBBSMfqBhIFWihr0lNarz10en9sQA%3D%3D)\n",
        "\n",
        "So we will have to convert our numbers to letters:\n",
        "\n",
        "I've created a handy function to do just that below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g9_4cq-KDJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  display first 5 images with the letters they represent:\n",
        "\n",
        "# create function to convert number to letter\n",
        "def number_to_letter(number):\n",
        "  return chr(number+65)\n",
        "\n",
        "for i in range(5):\n",
        "  \n",
        "  # display (letter) label\n",
        "  print(number_to_letter(y[i]))\n",
        "\n",
        "  img = np.reshape(X[i], (28, 28))\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DV7tNadKhRE",
        "colab_type": "text"
      },
      "source": [
        "Use this chart to see if they are correct:\n",
        "\n",
        "![alt text](https://storage.googleapis.com/kagglesdsdata/datasets/3258/5337/american_sign_language.PNG?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1561662820&Signature=NSMus25rd68OldMYcS2eiSR4Pe0rdycmn%2BL19ww5tM7YBeOPp6jS39Ktbqhae6IS7IeOroQ3iQziZF2LJAPXH7WDDhh2wU%2BkPDRibhTpbd9kdGaWn6IPqMpsyAcoNnSomK1mCQJ80VjcEcOlYrVT8V35ZhqtdY6YKFQpgZKXNnmEDGKaWt%2BpVe3sX6meIXTlOXo1csfBMzFTd1405wiYyYe97hEe9oDZDonHFSHjf5WpmRM7UXkjvRa9tb1mHOixZIf4NlJEYivNakh9F0LzLQs6dFegNZRpbqNsZj8qeutZYyrSI56HE4%2F%2FRBxMSXgMr5pf%2F%2FeyBIaS1eYhwcHbGw%3D%3D)\n",
        "\n",
        "They are? yes? cool, we can proceed..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDTluA2KLCC-",
        "colab_type": "text"
      },
      "source": [
        "## Train/Test spliting our data\n",
        "Like students being testing in a class room, if you give them the same test twise they'll just need to memorise the answers without actually learning the underlying consept. Thus when then they enter the real world and are faced with unseen problem, they will have no clue. \n",
        "\n",
        "So we will split our data into **training** data which the CNN will get to see and learning from, and **testing** data that it dosn't get to see during training, but we will use to make sure the CNN is actually learning.\n",
        "\n",
        "We can use the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) module from [sklearn](https://scikit-learn.org) to do this for us:\n",
        "\n",
        "```python\n",
        "# import module \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# while we are here, let's reshape all of our images at once\n",
        "X_reshaped = np.reshape(X, (len(X), original image height, original image width, 1))\n",
        "\n",
        "# split our data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_reshaped, y, test_size=0.20, random_state=42)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5Iu7twHNYHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] import the module, reshape all of the images, perform the train/test split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldckCf0GOQWg",
        "colab_type": "text"
      },
      "source": [
        "Let's have a peek at the dimensions (shape) of our data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96L5JrOoNqKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's quickly check the dimensions of our data\n",
        "print(\"training input data - \", X_train.shape)\n",
        "print(\"testing input data - \", X_test.shape)\n",
        "\n",
        "print(\"training output data - \", y_train.shape)\n",
        "print(\"testing output data - \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYJMWJ1VOsZA",
        "colab_type": "text"
      },
      "source": [
        "## Hold the phone! What does our output data look like?\n",
        "\n",
        "Print out the first 10 outputs:\n",
        "\n",
        "```python\n",
        "print(y_train[:10])\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGdbUae6O-sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] print out the first 10 outputs\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui0QE2zUPFd8",
        "colab_type": "text"
      },
      "source": [
        "### Hmmmmmm, we have an issue with this:\n",
        "<img height=300px src=\"https://storage.googleapis.com/random-assets/images/not_impressed_doggo.jpg\">\n",
        "\n",
        "Although we did agree that it's fine that our labels are numbers (becuase we can easily convert them to the ASL letters), our Convolutional Neural Network agreed to no such thing! In fact our CNN is alot more picky, it wants them as a [One-hot-encoded](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) matrix!!!\n",
        "\n",
        "It's all becuase of the structure of the CNN! Specifically the last layer, which is a singel node for each possible label (every letter of the alphabet in this case):\n",
        "\n",
        "![alt text](https://storage.googleapis.com/random-assets/images/one_hot_cnn.png)\n",
        "\n",
        "So let's quickly convert our number labels to the right format for the CNN (One-hot-encoded):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_PP0-9zTyb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert our output numbers to the one-hot-encoded version\n",
        "import keras\n",
        "\n",
        "# get our data again\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_reshaped, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# encode the outputs (y's) as one-hot\n",
        "y_train = keras.utils.to_categorical(y_train, 25)\n",
        "y_test = keras.utils.to_categorical(y_test, 25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUQme6ePU0rC",
        "colab_type": "text"
      },
      "source": [
        "Let's peek at teh new shape of our out data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uewxlbo3UFB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's quickly check the dimensions of our data\n",
        "print(\"training input data - \", X_train.shape)\n",
        "print(\"testing input data - \", X_test.shape)\n",
        "\n",
        "print(\"training output data - \", y_train.shape)\n",
        "print(\"testing output data - \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK-26dugVJU-",
        "colab_type": "text"
      },
      "source": [
        "Ok but what does it actually look like now:\n",
        "\n",
        "Print out the first 10 outputs:\n",
        "```python\n",
        "print(y_train[:10])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qBGK2WXVY0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] print out the first 10 outputs\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfgFp-ciVeM1",
        "colab_type": "text"
      },
      "source": [
        "### That might look ugly to us, but beautiful to our Convolutional Neural Network üòç"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17JJnAVskVFi",
        "colab_type": "text"
      },
      "source": [
        "# Time to build the Convolutional Neural Network!!!\n",
        "\n",
        "![alt text](https://storage.googleapis.com/random-assets/images/excited_pup.gif)\n",
        "\n",
        "What's not that exciting is that we are just going to copy and past the same CNN that is in the [keras github for solving the mnist handwriting problem](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py). \n",
        "\n",
        "### This is pragmatic ML: find a model that does something similar and copy it!\n",
        "\n",
        "*machine learning is all about adapting to new patterns*\n",
        "\n",
        "here's teh code to build our model:\n",
        "\n",
        "\n",
        "```python\n",
        "# build new Convolutional Neural Network!\n",
        "\n",
        "#import the nessasary keras modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "# start a new model\n",
        "model = Sequential()\n",
        "\n",
        "# create input layer (be sure to tell it the shape of data to expect)\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(ORIGINAL WIDTH OF IMAGE, ORIGINAL HEIGHT OF IMAGE, 1)))\n",
        "\n",
        "# add soem more layers, why not!\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# you can change all of the previous stuff (except the input layer) and the following \"output\" layer\n",
        "# be sure to fill in the shape of our output layer\n",
        "model.add(Dense(THE WIDTH OF OUR ONE-HOT-ENCODED OUTPUT MATRIX, activation='softmax'))\n",
        "\n",
        "# compile our model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3nJq5FhVX-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] build new Convolutional Neural Network!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cTPEKdmZwk9",
        "colab_type": "text"
      },
      "source": [
        "##<font color=red> Don't worry about any warnings above</font> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5yZwlLqBWrw",
        "colab_type": "text"
      },
      "source": [
        "## Let's train our CNN\n",
        "Use the following code to train the CNN:\n",
        "\n",
        "```python\n",
        "# train our CNN on our training data for 5 epochs (cycles through our dataset)\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "# print out the final accuracy scores of our CNN          \n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNgF87-ivC7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] run the training process\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70cA0_s-b9A9",
        "colab_type": "text"
      },
      "source": [
        "## Let's look at some predictions from our newly trained CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7pz_R3gb8gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fetch predictions for the first 10 TEST images (images not seen by CNN)\n",
        "model.predict_classes(X_test[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCoe1V2Ec6uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fetch predictions, convert them to letters\n",
        "predictions = [number_to_letter(l) for l in model.predict_classes(X_test[:10])]\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QUiulqEdslY",
        "colab_type": "text"
      },
      "source": [
        "Let's actually look at the predictions alongside the input images and see if they are correct:\n",
        "\n",
        "Use this chart to see if they are correct:\n",
        "\n",
        "![alt text](https://storage.googleapis.com/kagglesdsdata/datasets/3258/5337/american_sign_language.PNG?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1561662820&Signature=NSMus25rd68OldMYcS2eiSR4Pe0rdycmn%2BL19ww5tM7YBeOPp6jS39Ktbqhae6IS7IeOroQ3iQziZF2LJAPXH7WDDhh2wU%2BkPDRibhTpbd9kdGaWn6IPqMpsyAcoNnSomK1mCQJ80VjcEcOlYrVT8V35ZhqtdY6YKFQpgZKXNnmEDGKaWt%2BpVe3sX6meIXTlOXo1csfBMzFTd1405wiYyYe97hEe9oDZDonHFSHjf5WpmRM7UXkjvRa9tb1mHOixZIf4NlJEYivNakh9F0LzLQs6dFegNZRpbqNsZj8qeutZYyrSI56HE4%2F%2FRBxMSXgMr5pf%2F%2FeyBIaS1eYhwcHbGw%3D%3D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrqhogV9dQvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show predictions with input images\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"prediction = \", predictions[i])\n",
        "  plt.imshow(X_test[i,:,:,0])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP4LGVffeFZL",
        "colab_type": "text"
      },
      "source": [
        "# Congrats on building a sign language detecting Convolutional Neural Network ‚úã\n",
        "\n",
        "If you found that useful: feel free to let use know with a tweet:\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?text=Learning+about+interpreting+%23CNNs+using+the+SHAP+library+with+%23keras+on+%40GoogleColab+notebooks.+%0D%0AThanks+%40datalondon+%26+%40zackakil+for+the+awesome+meetup%21+%23datalondon+%23datascience+%23machinelearning+%0D%0Ahttps%3A%2F%2Frebrand.ly%2FCLDS-meetup-june25\"><img src=\"https://storage.googleapis.com/events_public_polong/CLDS_Meetups/CLDS_tweet_20190625.png\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHYCqPA_enma",
        "colab_type": "text"
      },
      "source": [
        "# But wait! There's more! Let's see what our CNN sees! üßê\n",
        "\n",
        "There is a big push for more understanding around the kind of model that you have just built. [SHAP](https://github.com/slundberg/shap) is a tool that helps you do just that, by highlighting the areas of an image that the Convolutional Neural Network used most in making its' prediction.\n",
        "\n",
        "\n",
        "![alt text](https://storage.googleapis.com/random-assets/images/shap.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JNpmNuNfwiB",
        "colab_type": "text"
      },
      "source": [
        "## Let's run it on our CNN for the test data:\n",
        "\n",
        "But first we need to install it in Colab (becuase it is not a standard ML package)\n",
        "\n",
        "Install SHAP with teh following command:\n",
        "```bash\n",
        "!pip install shap \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VPoox8Kf-OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [TASK] install SHAP\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z30II1PygYPO",
        "colab_type": "text"
      },
      "source": [
        "## We'll cut to the chase becuase it's currently abit fiddely to use\n",
        "\n",
        "straight from the [SHAP documentation](https://github.com/slundberg/shap):\n",
        "\n",
        "---\n",
        "*Predictions for two input images are explained in the plot [below]. Red pixels represent positive SHAP values that increase the probability of the class, while blue pixels represent negative SHAP values the reduce the probability of the class. By using ranked_outputs=2 we explain only the two most likely classes for each input (this spares us from explaining all [25] classes).*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxGzZh4-dkpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shap\n",
        "import keras.backend as K\n",
        "\n",
        "layer_to_explain = model.layers[1].input\n",
        "data_to_explain = X_test[:10]\n",
        "\n",
        "sess = K.get_session().run(layer_to_explain, {model.layers[0].input: X_train[:300]})\n",
        "explainer = shap.GradientExplainer( (layer_to_explain, model.layers[-1].output), sess)\n",
        "\n",
        "sess2 = K.get_session().run(layer_to_explain, {model.layers[0].input: data_to_explain })\n",
        "shap_values, indexes = explainer.shap_values(sess2, ranked_outputs=2)\n",
        "\n",
        "shap.image_plot(shap_values,  data_to_explain, np.vectorize(number_to_letter)(indexes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CAy6Fegigt8",
        "colab_type": "text"
      },
      "source": [
        "# There you go!, You've built a CNN, and explained it's predictions!! üèÅ"
      ]
    }
  ]
}